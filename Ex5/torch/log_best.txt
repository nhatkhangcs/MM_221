Epoch: 1000, train loss: 4.1223574, test loss: 3.0076456
Epoch: 2000, train loss: 2.2875540, test loss: 1.8380495
Epoch: 3000, train loss: 1.7223285, test loss: 1.4307202
Epoch: 4000, train loss: 1.4717906, test loss: 1.2483180
Epoch: 5000, train loss: 1.3422108, test loss: 1.1543493
Epoch: 6000, train loss: 1.2563493, test loss: 1.0925510
Epoch: 7000, train loss: 1.1904566, test loss: 1.0448304
Epoch: 8000, train loss: 1.1399810, test loss: 1.0078417
Epoch: 9000, train loss: 1.1031008, test loss: 0.9806384
Epoch: 10000, train loss: 1.0768491, test loss: 0.9612966
Epoch: 11000, train loss: 1.0580199, test loss: 0.9475259
Epoch: 12000, train loss: 1.0441535, test loss: 0.9375010
Epoch: 13000, train loss: 1.0334960, test loss: 0.9298927
Epoch: 14000, train loss: 1.0250108, test loss: 0.9239108
Epoch: 15000, train loss: 1.0179945, test loss: 0.9190186
Epoch: 16000, train loss: 1.0120858, test loss: 0.9149400
Epoch: 17000, train loss: 1.0070142, test loss: 0.9114723
Epoch: 18000, train loss: 1.0025977, test loss: 0.9084774
Epoch: 19000, train loss: 0.9986944, test loss: 0.9058498
Epoch: 20000, train loss: 0.9952396, test loss: 0.9035412
Epoch: 21000, train loss: 0.9921512, test loss: 0.9014937
Epoch: 22000, train loss: 0.9894038, test loss: 0.8996859
Epoch: 23000, train loss: 0.9869529, test loss: 0.8980875
Epoch: 24000, train loss: 0.9847055, test loss: 0.8966296
Epoch: 25000, train loss: 0.9827152, test loss: 0.8953536
Epoch: 26000, train loss: 0.9809129, test loss: 0.8942069
Epoch: 27000, train loss: 0.9792514, test loss: 0.8931581
Epoch: 28000, train loss: 0.9777567, test loss: 0.8922249
Epoch: 29000, train loss: 0.9764268, test loss: 0.8914054
Epoch: 30000, train loss: 0.9751797, test loss: 0.8906423
tensor([[-1.9884,  2.9663]])
Model loaded from "fit/netfit_softplus.pt"
Epoch: 500, train loss: 9.0678577, test loss: 9.9455051
Epoch: 1000, train loss: 4.8617659, test loss: 5.5492458
Epoch: 1500, train loss: 3.6320066, test loss: 4.1040416
Epoch: 2000, train loss: 3.2724543, test loss: 3.5950670
Epoch: 2500, train loss: 3.1673265, test loss: 3.3995175
Epoch: 3000, train loss: 3.1365902, test loss: 3.3170755
Epoch: 3500, train loss: 3.1276050, test loss: 3.2793107
Epoch: 4000, train loss: 3.1249788, test loss: 3.2608807
Epoch: 4500, train loss: 3.1242092, test loss: 3.2515054
Epoch: 5000, train loss: 3.1239834, test loss: 3.2466013
Epoch: 5500, train loss: 3.1239188, test loss: 3.2440012
Epoch: 6000, train loss: 3.1238987, test loss: 3.2426069
Epoch: 6500, train loss: 3.1238942, test loss: 3.2418473
Epoch: 7000, train loss: 3.1238909, test loss: 3.2414417
Epoch: 7500, train loss: 3.1238921, test loss: 3.2412231
Epoch: 8000, train loss: 3.1238916, test loss: 3.2411165
Epoch: 8500, train loss: 3.1238911, test loss: 3.2410767
Epoch: 9000, train loss: 3.1238911, test loss: 3.2410767
Epoch: 9500, train loss: 3.1238911, test loss: 3.2410767
Epoch: 10000, train loss: 3.1238911, test loss: 3.2410767
Epoch: 10500, train loss: 3.1238911, test loss: 3.2410767
Epoch: 11000, train loss: 3.1238911, test loss: 3.2410767
Epoch: 11500, train loss: 3.1238911, test loss: 3.2410767
Epoch: 12000, train loss: 3.1238911, test loss: 3.2410767
Epoch: 12500, train loss: 3.1238911, test loss: 3.2410767
Epoch: 13000, train loss: 3.1238911, test loss: 3.2410767
Epoch: 13500, train loss: 3.1238911, test loss: 3.2410767
Epoch: 14000, train loss: 3.1238911, test loss: 3.2410767
Epoch: 14500, train loss: 3.1238911, test loss: 3.2410767
Epoch: 15000, train loss: 3.1238911, test loss: 3.2410767
Epoch: 15500, train loss: 3.1238911, test loss: 3.2410767
Epoch: 16000, train loss: 3.1238911, test loss: 3.2410767
Epoch: 16500, train loss: 3.1238911, test loss: 3.2410767
Epoch: 17000, train loss: 3.1238911, test loss: 3.2410767
Epoch: 17500, train loss: 3.1238911, test loss: 3.2410767
Epoch: 18000, train loss: 3.1238911, test loss: 3.2410767
Epoch: 18500, train loss: 3.1238911, test loss: 3.2410767
Epoch: 19000, train loss: 3.1238911, test loss: 3.2410767
Epoch: 19500, train loss: 3.1238911, test loss: 3.2410767
Epoch: 20000, train loss: 3.1238911, test loss: 3.2410767
OrderedDict([('linear.weight', tensor([[ 2.2064,  3.6827],
        [ 5.5315, -2.4387]]))])